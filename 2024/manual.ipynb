import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse

def download_file(url, folder):
    # Ensure the folder structure exists
    if not os.path.exists(folder):
        os.makedirs(folder)
    
    local_filename = os.path.join(folder, os.path.basename(urlparse(url).path))
    with requests.get(url, stream=True) as response:
        if response.status_code == 200:
            with open(local_filename, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
    return local_filename

def download_website_resources(url, download_folder):
    # Create download folder if it doesn't exist
    if not os.path.exists(download_folder):
        os.makedirs(download_folder)

    # Download the main HTML page
    response = requests.get(url)
    if response.status_code != 200:
        print(f"Failed to retrieve the page: {response.status_code}")
        return

    # Parse the HTML using BeautifulSoup
    soup = BeautifulSoup(response.text, 'html.parser')
    html_file_path = os.path.join(download_folder, 'index.html')
    with open(html_file_path, 'w', encoding='utf-8') as file:
        file.write(soup.prettify())

    # Download CSS and JavaScript files
    tags = {'link': 'href', 'script': 'src'}
    for tag, attribute in tags.items():
        for resource in soup.find_all(tag):
            resource_url = resource.get(attribute)
            if resource_url:
                resource_url = urljoin(url, resource_url)
                folder_name = 'css' if tag == 'link' else 'js'
                resource_folder = os.path.join(download_folder, folder_name)
                if tag == 'link' and resource.get('rel') == ['stylesheet']:
                    download_file(resource_url, resource_folder)
                elif tag == 'script':
                    download_file(resource_url, resource_folder)

    # Download images
    for img in soup.find_all('img'):
        img_url = img.get('src')
        if img_url:
            img_url = urljoin(url, img_url)
            img_folder = os.path.join(download_folder, 'images')
            download_file(img_url, img_folder)

    # Download other resources (e.g., layers)
    for script in soup.find_all('script'):
        script_url = script.get('src')
        if script_url and 'layers' in script_url:
            script_url = urljoin(url, script_url)
            layers_folder = os.path.join(download_folder, 'layers')
            download_file(script_url, layers_folder)

    print(f"Downloaded resources to folder: {download_folder}")

# Example usage
website_url = 'https://0404.go.kr/new_osm/index_x.jsp?a1=15571139.906030&a2=4476152.376380&a3=1&a4='
download_folder = 'folium_241013'
download_website_resources(website_url, download_folder)
